{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1452f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd187a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter the name of image with extensionSudoku.jpg\n"
     ]
    }
   ],
   "source": [
    "name=input(\"please enter the name of image with extension\")\n",
    "IMAGE_PATH = \"Input_images\"\n",
    "IMAGE_PATH =os.path.join(IMAGE_PATH,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0d8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(IMAGE_PATH)\n",
    "img=cv2.resize(img,(500,500))\n",
    "image=img.copy()\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,51,9)\n",
    "kernel = np.ones((5,5), np.uint8) \n",
    "thresh = cv2.dilate(thresh, kernel, iterations=1)\n",
    "thresh = cv2.erode(thresh, kernel, iterations=1)\n",
    "# cv2.imshow(\"x\",thresh)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "img = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1b34e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361.0    361.0\n",
      "((249.5, 249.5), (361.0, 361.0), 90.0)\n"
     ]
    }
   ],
   "source": [
    "cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "area_treshold = 1000\n",
    "o=np.zeros((600,600))\n",
    "# cv2.drawContours(img, cnts[0], -1, (0, 255, 0), 3)\n",
    "center=[]\n",
    "maxx=0\n",
    "maxy=0\n",
    "for c in cnts:\n",
    "    x=cv2.minAreaRect(c)\n",
    "    if(x[1][0]>maxx):\n",
    "        maxx=x[1][0]\n",
    "    if(x[1][1]>maxy):\n",
    "        maxy=x[1][1]\n",
    "     \n",
    "\n",
    "for c in cnts:\n",
    "   \n",
    "#     cv2.drawContours(img, [c], -1, (0, 255, 0), 3)\n",
    "#       x,y,w,h = cv2.boundingRect(c)\n",
    "#       cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 3)\n",
    "    x=cv2.minAreaRect(c)\n",
    "    if x[1][0]==maxx:\n",
    "        center.append(int(x[0][0]-x[1][1]/2))\n",
    "        center.append(int(x[0][1]-x[1][0]/2))\n",
    "print(f\"{x[1][0]}    {x[1][1]}\")\n",
    "#     cv2.polylines(o,[b],True,(0,255,0),2)\n",
    "#     break\n",
    "# img=image[50:180, 100:300]\n",
    "print(x)\n",
    "# cv2.drawContours(img, cnts, -1, (0, 255, 0), 3)\n",
    "# cv2.imshow(\"one\",img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cdb68db",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image[int(center[0]+5):int(center[0]+maxx-5),int(center[1]+5):int(center[1]+maxy-5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593ca76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trans=transforms.Compose([\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.,0.,0.],\n",
    "                        [1.0,1.0,1.0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf2313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class one(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1=nn.Conv2d(3,12,kernel_size=3,stride=1,padding=1)\n",
    "        self.b1=nn.BatchNorm2d(12)\n",
    "        self.r1=nn.ReLU()\n",
    "        self.p1=nn.MaxPool2d(kernel_size = 2, stride=2)\n",
    "        self.c2=nn.Conv2d(12,20,kernel_size=3,stride=1,padding=1)\n",
    "        self.r2=nn.ReLU()\n",
    "        self.c3=nn.Conv2d(20,32,kernel_size=3,stride=1,padding=1)\n",
    "        self.r3=nn.ReLU()\n",
    "        self.b3=nn.BatchNorm2d(32)\n",
    "        self.l=nn.Linear(32*25*25,10)\n",
    "    def forward(self,x):\n",
    "        o=self.c1(x)\n",
    "        o=self.b1(o)\n",
    "        o=self.r1(o)\n",
    "        o=self.p1(o)\n",
    "        o=self.c2(o)\n",
    "        o=self.r2(o)\n",
    "        o=self.c3(o)\n",
    "        o=self.b3(o)\n",
    "        o=self.r3(o)\n",
    "        o=o.view(-1,32*25*25)\n",
    "        o=self.l(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6180ce62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one(\n",
       "  (c1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (b1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (r1): ReLU()\n",
       "  (p1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (r2): ReLU()\n",
       "  (c3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (r3): ReLU()\n",
       "  (b3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l): Linear(in_features=20000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint=torch.load('best.model',torch.device(device))\n",
    "model=one()\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9227c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 4 0 5 0 0 0 0 \n",
      "9 0 0 7 3 4 6 0 0 \n",
      "0 0 3 0 2 1 0 4 9 \n",
      "0 3 5 0 9 0 4 8 0 \n",
      "0 9 0 0 0 0 0 3 0 \n",
      "0 7 6 0 1 0 9 2 0 \n",
      "3 1 0 9 7 0 2 0 0 \n",
      "0 0 9 1 8 2 0 0 3 \n",
      "0 0 0 0 6 0 1 0 0 \n"
     ]
    }
   ],
   "source": [
    "img=cv2.resize(img,(450,450))\n",
    "a=[]\n",
    "ans=[]\n",
    "ans1=[]\n",
    "k=0\n",
    "for i in range(9):\n",
    "    \n",
    "    for j in range(9):\n",
    "        d=int((j+1)/3)\n",
    "        d1=int((i+1)/3)\n",
    "        num=img[i*50+8+d1*2:(i+1)*50-10+d1*1,j*50+11+d*2:(j+1)*50-16+d*2]\n",
    "        n=num.copy()\n",
    "#         num=img[i*50+15:(i+1)*50-5,j*50+10:(j+1)*50-15]\n",
    "        \n",
    "        num=cv2.resize(num,(28,40))\n",
    "        cv2.imwrite(\"store\\\\one.png\",num)\n",
    "        image=Image.open(\"store\\\\one.png\")\n",
    "        image_tensor=trans(image).float()\n",
    "        image_tensor=image_tensor.unsqueeze_(0)\n",
    "        \n",
    "        input=torch.autograd.Variable(image_tensor)\n",
    "        num=cv2.cvtColor(num,cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(num,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,51,9)\n",
    "        cnts,_ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "      \n",
    "        if len(cnts)==0:\n",
    "            print(0,end=\" \")\n",
    "            a.append(0)\n",
    "            ans1.append([i,j])\n",
    "        else:\n",
    "            o=model(input)\n",
    "            index=o.data.numpy().argmax()\n",
    "            print(index,end=\" \")\n",
    "            a.append(index)\n",
    "    ans.append(a)\n",
    "    \n",
    "    a=[]\n",
    "    print()\n",
    "# num=img[310:340,15:40]\n",
    "# cv2.imshow(\"x\",img)\n",
    "# plt.imshow(num)\n",
    "# plt.show()\n",
    "# # cv2.imshow(\"y\",num)\n",
    "# cv2.imwrite(\"one.jpg\",num)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fff8bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(ans1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2e624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3016d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "def isSafe(grid, row, col, num):\n",
    " \n",
    "\n",
    "    for x in range(9):\n",
    "        if grid[row][x] == num:\n",
    "            return False\n",
    " \n",
    "\n",
    "    for x in range(9):\n",
    "        if grid[x][col] == num:\n",
    "            return False\n",
    " \n",
    "  \n",
    "    startRow = row - row % 3\n",
    "    startCol = col - col % 3\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if grid[i + startRow][j + startCol] == num:\n",
    "                return False\n",
    "    return True\n",
    " \n",
    "\n",
    "def solveSudoku(grid, row, col):\n",
    " \n",
    " \n",
    "    if (row == N - 1 and col == N):\n",
    "        return True\n",
    "     \n",
    "    \n",
    "    if col == N:\n",
    "        row += 1\n",
    "        col = 0\n",
    " \n",
    "    \n",
    "    if grid[row][col] > 0:\n",
    "        return solveSudoku(grid, row, col + 1)\n",
    "    for num in range(1, N + 1, 1):\n",
    "     \n",
    "        \n",
    "        if isSafe(grid, row, col, num):\n",
    "         \n",
    "            \n",
    "            grid[row][col] = num\n",
    " \n",
    "            \n",
    "            if solveSudoku(grid, row, col + 1):\n",
    "                return True\n",
    " \n",
    "      \n",
    "        grid[row][col] = 0\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14b11da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(solveSudoku(ans, 0, 0)):\n",
    "    print(\"Sudoku solved...\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5dd31e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    \n",
    "    for j in range(9):\n",
    "        d=int((j+1)/3)\n",
    "        d1=int((i+1)/3)\n",
    "        \n",
    "        if [j,i] in ans1:\n",
    "            x=(i*50+8+d1*2+(i+1)*50-10+d1*1)/2-15\n",
    "            y=(j*50+11+d*2+(j+1)*50-16+d*2)/2+15\n",
    "            cv2.putText(img,f\"{ans[j][i]}\",(int(x),int(y)),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)\n",
    "           \n",
    "cv2.imshow(\"one\",img)\n",
    "OUTPUT_PATH=os.path.join(\"Results\",\"Solved_\"+name)\n",
    "cv2.imwrite(OUTPUT_PATH,img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1bb9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b39e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
